#!/bin/bash
# ğŸš€ BGE-M3 Danbooruè®­ç»ƒä¸€é”®è„šæœ¬
# =================================

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

echo "ğŸ¯ Starting BGE-M3 Danbooru Training Pipeline..."

# é…ç½®å‚æ•°
MODEL_NAME="BAAI/bge-m3"
DB_DIR="artifacts/vector_stores/chroma_db"
OUTPUT_FILE="danbooru_tags.jsonl"
BATCH_SIZE=32
MAX_ITEMS=""

# è§£æå‘½ä»¤è¡Œå‚æ•°
while [[ $# -gt 0 ]]; do
    case $1 in
        --model)
            MODEL_NAME="$2"
            shift 2
            ;;
        --batch-size)
            BATCH_SIZE="$2"
            shift 2
            ;;
        --max-items)
            MAX_ITEMS="--max-items $2"
            shift 2
            ;;
        --db-dir)
            DB_DIR="$2"
            shift 2
            ;;
        --help)
            echo "Usage: $0 [options]"
            echo "Options:"
            echo "  --model MODEL_NAME    BGE model to use (default: BAAI/bge-m3)"
            echo "  --batch-size SIZE     Batch size for training (default: 32)"
            echo "  --max-items NUM       Maximum items to process (for testing)"
            echo "  --db-dir DIR          ChromaDB directory (default: artifacts/vector_stores/chroma_db)"
            exit 0
            ;;
        *)
            echo "Unknown option: $1"
            exit 1
            ;;
    esac
done

# æ£€æŸ¥Pythonç¯å¢ƒ
echo "ğŸ“‹ Checking Python environment..."
python3 --version
if ! python3 -c "import torch; print(f'PyTorch: {torch.__version__}')"; then
    echo "âŒ PyTorch not found. Please install it first."
    exit 1
fi

if ! python3 -c "import FlagEmbedding; print('FlagEmbedding: OK')"; then
    echo "âŒ FlagEmbedding not found. Installing..."
    pip install FlagEmbedding>=1.3.0
fi

# æ£€æŸ¥GPU
echo "ğŸ” Checking GPU availability..."
if python3 -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"; then
    python3 -c "import torch; print(f'GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"
    python3 -c "import torch; print(f'GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB' if torch.cuda.is_available() else 'N/A')"
fi

# åˆ›å»ºå¿…è¦ç›®å½•
echo "ğŸ“ Creating directories..."
mkdir -p artifacts/vector_stores
mkdir -p artifacts/logs
mkdir -p artifacts/models

# æ­¥éª¤1: æ•°æ®å‡†å¤‡
echo "ğŸ”„ Step 1: Preparing Danbooru data..."
if [[ ! -f "$OUTPUT_FILE" ]]; then
    echo "ğŸ“¥ Preparing data from local sources..."
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æœ¬åœ°æ•°æ®é›†
    if [[ -f "danbooru2024_complete.parquet" ]]; then
        python3 prepare_danbooru_data.py \
            --source-type local \
            --source-path danbooru2024_complete.parquet \
            --format parquet \
            --output "$OUTPUT_FILE" \
            $MAX_ITEMS
    elif [[ -f "danbooru_tags_2024.txt" ]]; then
        python3 prepare_danbooru_data.py \
            --source-type tags \
            --source-path danbooru_tags_2024.txt \
            --output "$OUTPUT_FILE" \
            $MAX_ITEMS
    else
        echo "âš ï¸  No local dataset found. Creating sample data..."
        python3 -c "
import json
sample_data = [
    {'id': '1', 'text': 'ã€é€šç”¨ã€‘1girl - å•ä¸ªå¥³æ€§è§’è‰²ã€‚è¿™æ˜¯æœ€åŸºç¡€çš„è§’è‰²æ ‡ç­¾', 'source': 'danbooru'},
    {'id': '2', 'text': 'ã€æœè£…ã€‘school_uniform - å­¦ç”Ÿåˆ¶æœã€‚åŒ…æ‹¬æ°´æ‰‹æœã€è¥¿å¼åˆ¶æœç­‰', 'source': 'danbooru'},
    {'id': '3', 'text': 'ã€ç”»å¸ˆã€‘kantoku - ä¸“é—¨åˆ›ä½œèŒç³»é£æ ¼ä½œå“çš„è‘—åæ’ç”»å¸ˆ', 'source': 'danbooru'},
    {'id': '4', 'text': 'ã€è§’è‰²ã€‘hatsune_miku - æ¥è‡ªVOCALOIDçš„è™šæ‹Ÿæ­Œæ‰‹ï¼ŒåŒé©¬å°¾ç»¿å‘ç‰¹å¾', 'source': 'danbooru'},
    {'id': '5', 'text': 'ã€é€šç”¨ã€‘masterpiece - é«˜è´¨é‡ä½œå“æ ‡ç­¾ï¼Œç”¨äºæå‡å›¾åƒæ•´ä½“è´¨é‡', 'source': 'danbooru'}
]
with open('$OUTPUT_FILE', 'w', encoding='utf-8') as f:
    for item in sample_data:
        f.write(json.dumps(item, ensure_ascii=False) + '\n')
print(f'Created sample data: $OUTPUT_FILE')
"
    fi
else
    echo "âœ… Data file already exists: $OUTPUT_FILE"
fi

# éªŒè¯æ•°æ®æ–‡ä»¶
echo "ğŸ” Validating data file..."
if [[ -f "$OUTPUT_FILE" ]]; then
    line_count=$(wc -l < "$OUTPUT_FILE")
    echo "ğŸ“Š Data file contains $line_count lines"
    echo "ğŸ“ Sample data:"
    head -3 "$OUTPUT_FILE"
else
    echo "âŒ Data file not found: $OUTPUT_FILE"
    exit 1
fi

# æ­¥éª¤2: å‘é‡åŒ–è®­ç»ƒ
echo "ğŸš€ Step 2: Starting vectorization training..."
echo "ğŸ¯ Model: $MODEL_NAME"
echo "ğŸ“¦ Batch size: $BATCH_SIZE"
echo "ğŸ’¾ Database: $DB_DIR"

# è®¾ç½®ç¯å¢ƒå˜é‡
export TOKENIZERS_PARALLELISM=false
export TRANSFORMERS_VERBOSITY=error

# æ ¹æ®GPUå†…å­˜è°ƒæ•´æ‰¹æ¬¡å¤§å°
if python3 -c "import torch; exit(0 if torch.cuda.is_available() and torch.cuda.get_device_properties(0).total_memory < 8e9 else 1)"; then
    echo "âš ï¸  Low GPU memory detected. Reducing batch size to 16"
    BATCH_SIZE=16
fi

# æ‰§è¡Œè®­ç»ƒ
python3 vectorizer.py \
    --input "$OUTPUT_FILE" \
    --db "$DB_DIR" \
    --model "$MODEL_NAME" \
    --batch-size "$BATCH_SIZE" \
    2>&1 | tee "artifacts/logs/training_$(date +%Y%m%d_%H%M%S).log"

# æ£€æŸ¥è®­ç»ƒç»“æœ
echo "ğŸ” Checking training results..."
if [[ -d "$DB_DIR" ]]; then
    echo "âœ… Vector database created successfully"
    
    # æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡
    python3 -c "
import chromadb
try:
    client = chromadb.PersistentClient(path='$DB_DIR')
    collections = client.list_collections()
    for collection in collections:
        count = collection.count()
        print(f'Collection: {collection.name}, Documents: {count}')
except Exception as e:
    print(f'Error reading database: {e}')
"
else
    echo "âŒ Vector database not found"
    exit 1
fi

# æ­¥éª¤3: æµ‹è¯•æœç´¢åŠŸèƒ½
echo "ğŸ§ª Step 3: Testing search functionality..."
python3 -c "
import chromadb
import sys

try:
    client = chromadb.PersistentClient(path='$DB_DIR')
    collections = client.list_collections()
    
    if not collections:
        print('âŒ No collections found')
        sys.exit(1)
    
    collection = collections[0]
    print(f'ğŸ” Testing search on collection: {collection.name}')
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = ['1girl anime', 'school uniform', 'high quality']
    
    for query in test_queries:
        try:
            results = collection.query(
                query_texts=[query],
                n_results=3
            )
            print(f'Query: \"{query}\" -> {len(results[\"documents\"][0])} results')
            for i, doc in enumerate(results['documents'][0][:2]):
                print(f'  {i+1}. {doc[:100]}...')
        except Exception as e:
            print(f'Query error for \"{query}\": {e}')
    
    print('âœ… Search functionality test completed')
    
except Exception as e:
    print(f'âŒ Search test failed: {e}')
    sys.exit(1)
"

# å®Œæˆ
echo "ğŸ‰ Training pipeline completed successfully!"
echo "ğŸ“ Vector database location: $DB_DIR"
echo "ğŸ“„ Training logs: artifacts/logs/"
echo "ğŸ”— You can now start the server with: python3 danbooru_prompt_server_v2_minimal.py"

# ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š
echo "ğŸ“Š Generating training report..."
cat > "artifacts/training_report_$(date +%Y%m%d_%H%M%S).md" << EOF
# BGE-M3 Danbooru Training Report

## Training Configuration
- **Model**: $MODEL_NAME
- **Batch Size**: $BATCH_SIZE
- **Database**: $DB_DIR
- **Data File**: $OUTPUT_FILE
- **Training Date**: $(date)

## System Information
- **Python Version**: $(python3 --version)
- **PyTorch Version**: $(python3 -c "import torch; print(torch.__version__)")
- **CUDA Available**: $(python3 -c "import torch; print(torch.cuda.is_available())")
- **GPU Name**: $(python3 -c "import torch; print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU')")

## Training Results
- **Status**: âœ… Completed Successfully
- **Vector Database**: Created at $DB_DIR
- **Collections**: $(python3 -c "import chromadb; client = chromadb.PersistentClient(path='$DB_DIR'); print(len(client.list_collections()))" 2>/dev/null || echo "Unknown")

## Next Steps
1. Start the server: \`python3 danbooru_prompt_server_v2_minimal.py\`
2. Test the API endpoints
3. Integrate with your AI art generation workflow

---
Generated by run_training.sh
EOF

echo "ğŸ“‹ Training report saved to: artifacts/training_report_$(date +%Y%m%d_%H%M%S).md"